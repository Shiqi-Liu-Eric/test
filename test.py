import pandas as pd
import numpy as np
from sklearn.linear_model import LogisticRegression
from xgboost import XGBClassifier
from sklearn.metrics import classification_report

# ========== è¯»å– SPY æ”¶ç›˜ä»· ========== #
spy = pd.read_csv("spy_close.csv", parse_dates=['date'])
spy = spy[['date', 'PX_LAST']].dropna().sort_values('date')
spy['spy_ret'] = spy['PX_LAST'].pct_change().shift(-1)
spy['target'] = (spy['spy_ret'] > 0).astype(int)

# ========== å¯¹é½æ—¥æœŸ ========== #
dates = pd.to_datetime(dfs['country_ftse_globalallcap'].columns)
valid_dates = sorted(set(dates) & set(spy['date']))
dates = np.array(valid_dates)
spy = spy[spy['date'].isin(valid_dates)].reset_index(drop=True)

# ========== æ„é€  US æ©ç çŸ©é˜µ ========== #
country_df = dfs['country_ftse_globalallcap'].loc[:, dates]
us_mask = (country_df == 'US').astype(float).values  # shape = (N_stocks, N_days)

# ========== æ„é€  Barra ç‰¹å¾å¼ é‡ ========== #
feature_tensor = np.array([
    dfs[f].loc[:, dates].fillna(0).values * us_mask for f in unique_descriptors
])  # shape = (64, N_stocks, N_days)

# ========== æ¯ä¸ªç‰¹å¾çš„æ€»å’Œï¼ˆå¯¹è‚¡ç¥¨ç»´æ±‚å’Œï¼‰ ========== #
feature_sum = feature_tensor.sum(axis=1)  # shape = (64, N_days)

# ========== æ„é€ ä¸¤ä¸ªç‰¹å¾é›† ========== #
# 1. å½“å¤© - å‰ä¸€å¤©
diff1 = feature_sum[:, 1:] - feature_sum[:, :-1]  # shape = (64, N_days - 1)

# 2. T-1~T-3 - T-4~T-6
sum_recent = feature_sum[:, 2:-3] + feature_sum[:, 3:-2] + feature_sum[:, 4:-1]
sum_past   = feature_sum[:, -6:-3] + feature_sum[:, -5:-2] + feature_sum[:, -4:-1]
diff3vs6   = sum_recent - sum_past  # shape = (64, N_days - 6)

# ========== å¯¹é½å¹¶æ‹¼æ¥ ========== #
min_len = min(diff1.shape[1], diff3vs6.shape[1])  # é˜²æ­¢è¶Šç•Œ
X_all = np.concatenate([diff1[:, -min_len:], diff3vs6[:, -min_len:]], axis=0).T  # shape = (days, 128)
X_dates = dates[6:6 + min_len]

# ========== æ„é€ ç‰¹å¾ DataFrame ========== #
X_df = pd.DataFrame(X_all, columns=[
    f'{f}_diff1' for f in unique_descriptors
] + [
    f'{f}_diff3vs6' for f in unique_descriptors
])
X_df['date'] = X_dates

# åˆå¹¶ targetï¼ˆSPYï¼‰
X_df = X_df.merge(spy[['date', 'target']], on='date').dropna()

# ========== åˆ’åˆ†è®­ç»ƒå’Œæµ‹è¯•é›† ========== #
X_train = X_df[X_df['date'].dt.year.isin([2021, 2022])].drop(columns=['date'])
X_test  = X_df[X_df['date'].dt.year == 2023].drop(columns=['date'])
y_train = X_train.pop('target')
y_test  = X_test.pop('target')

# ========== æ¨¡å‹è®­ç»ƒå’Œè¯„ä¼° ========== #
print("\nğŸ“˜ Logistic Regression:")
lr = LogisticRegression(max_iter=1000)
lr.fit(X_train, y_train)
y_pred_lr = lr.predict(X_test)
print(classification_report(y_test, y_pred_lr))

print("\nğŸ“— XGBoost Classifier:")
xgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)
xgb.fit(X_train, y_train)
y_pred_xgb = xgb.predict(X_test)
print(classification_report(y_test, y_pred_xgb))
